# GPT2 CUDA
This project is an implementation of the GPT2 model using C/CUDA. The main focus is to be able to implement this model exploring and abusing the computational power of GPUs and apply CUDA concepts that I learned. Also, one future feature is to perform a quantized traning, post-training quantization and eventually a multi-GPU training.  

This project is inspired by llm.c by karpathy (https://github.com/karpathy/llm.c).